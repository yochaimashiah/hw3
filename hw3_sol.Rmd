
---
title: "Network Analysis"
author: "yochai"
output: 
  md_document:
    variant: markdown_github
---

Setting a working directory:
```{r}
folder = 'C:\\Users\\DELL\\Desktop\\study\\year4\\DataS\\HW3'
setwd(folder)

#Or for all chuncks in this Rmarkdown:
knitr::opts_knit$set(root.dir = folder)
```

# Task 1:
Load Grey's Anatomy network of romances (ga_edgelist.csv).
```{r, message=FALSE, warning=FALSE}
#install.packages('igraph')
library(igraph)
ga.data <- read.csv('ga_edgelist.csv', header = T)
g <- graph.data.frame(ga.data,directed = F)
```


Calculate degree for the various nodes, set vertix size according to its degree and plot the graph.
```{r}
set.seed(123)
degr.score <- degree(g)
V(g)$size <- degr.score * 2 # multiply by 2 for scale 
plot(g) 
```


Calculate betweenness score-
The vertex betweenness are (roughly) defined by the number of geodesics (shortest paths) going through a vertex
```{r}
betweenness_score = betweenness(g)
betweenness_score = sort(betweenness_score, decreasing = TRUE)
betweenness_score
```
*sloan  115.36667


Calculate closeness-
Closeness is based on the length of the average shortest path between a node and all other nodes in the network.
Cloness centrality measures how many steps is required to access every other vertex from a given vertex.
```{r}
closeness_score = closeness(g, mode="all")
closeness_score = sort(closeness_score, decreasing = TRUE)
closeness_score
```
*torres 0.003194888


5.Eigenvector centrality score-
How central you are depends on how central your neighbors are.
Centrality is proportional to the sum of neighbors’ centralities.
```{r}
Eigenvector_score = eigen_centrality(g, directed = TRUE, scale = TRUE, weights = NULL,
  options = arpack_defaults)
Eigenvector_score
```
*karev 1.0


```{r, message=FALSE, warning=FALSE}
#install.packages("devtools")
#library(devtools)
```

```{r}
#install_github("Rfacebook", "pablobarbera", subdir="Rfacebook")
require (Rfacebook)
```

Analyze Facebook
```{r, message=FALSE, warning=FALSE}
tokenn='EAACEdEose0cBADD9bkpCWhZC0isw3hL87YS5tgFmPChKX9ZCV3dZBZA99FHAYSmXXkkZB0kTodY0lH00XZCarinOpgxxXCPBAIC8omgY52MI8fEl0fEfJ7WmWkyADgZCKOdkcY2kNihIbvC4ZAJqiuxvwdieibw6UY7fwz2LR3ZAYSNgenDugS2Hm'

```


Get 10 posts from page "cnnbrknews" from facebook
@cr extract the messages
@cr create Term-Document Matrix from the posts- without Punctuation and stopwords
@cr Build a term-Document graph that displays connections between terms that appear together in common posts
@cr Beautify our graph by setting the degree attribute (normlize the label size by dividing with maximal size).
@cr display plot of graph with kamada kawai algorithm
```{r}
#install.packages(tm)
library(tm)

load("fb_oauth")
#get data
fb_page <- getPage(page="cnnbrknews", token=fb_oauth, n=10)
corpus <- Corpus(VectorSource(fb_page$message))

#create term-Document Matrix
termDocMatrix=TermDocumentMatrix(corpus,control = list(removePunctuation = TRUE,
                                         stopwords = TRUE))
#create term-Document graph 
require(igraph)
net <- graph.incidence(termDocMatrix)

proj_net <- bipartite.projection(net)
net <- proj_net$proj1

#Beautify our graph
degr.score <- degree(net)
V(net)$size <- degr.score * 0.5 # multiply by 2 for scale 
V(net)$label.cex<-  2.2 * V(net)$size / max(V(net)$size) + .2

#print the graph 
l <- layout_with_kk(net)
plot(net, layout=l)
tkplot(net, layout=l)
summary(net)
```

calc betweenness_score
```{r}
betweenness_score = betweenness(net)
betweenness_score = sort(betweenness_score, decreasing = TRUE)
betweenness_score
```

calc closeness_score
```{r}
closeness_score = closeness(net, mode="all")
closeness_score = sort(closeness_score, decreasing = TRUE)
closeness_score
```

calc Eigenvector_score
```{r}
Eigenvector_score = eigen_centrality(net, scale = TRUE, weights = NULL,
  options = arpack_defaults)
Eigenvector_score
```

